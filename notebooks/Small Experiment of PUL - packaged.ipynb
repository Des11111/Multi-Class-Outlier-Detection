{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e523732-1e02-4333-821f-09d37e84a94a",
   "metadata": {},
   "source": [
    "# A Small Experiment of PU Learning\n",
    "\n",
    "This is to understanding how PU learning works in Multi-Class Outlier Detection cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb795d-5887-475c-bcd0-19489837f80a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749604a2-5165-48d9-9528-51658f0581f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This helps when you're loading functions defined in an external script (if the script is updated while the notebook is running)\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from mypackage.data_models import generate_data_uniform_plus_normal \n",
    "from mypackage.learning import compute_pu_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a9220",
   "metadata": {},
   "source": [
    "## New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c082f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate data\n",
    "dim = 50\n",
    "mean_c1=1\n",
    "mean_c2=-1\n",
    "radius=4\n",
    "a_signal=8\n",
    "\n",
    "# Training data\n",
    "n_in_1_train = 1000\n",
    "n_in_2_train = 10\n",
    "\n",
    "# Calibration data\n",
    "n_in_1_cal = 1000\n",
    "n_in_2_cal = 10\n",
    "\n",
    "# Test data\n",
    "n_in_1_test = 500\n",
    "n_in_2_test = 10\n",
    "n_out_test = 500\n",
    "\n",
    "X_train, Y_train = generate_data_uniform_plus_normal(n_in_1_train, n_in_2_train, 0, dim=dim, mean_c1=mean_c1, mean_c2=mean_c2, radius=radius, a_signal=a_signal)\n",
    "X_cal, Y_cal = generate_data_uniform_plus_normal(n_in_1_cal, n_in_2_cal, 0, dim=dim, mean_c1=mean_c1, mean_c2=mean_c2, radius=radius, a_signal=a_signal)\n",
    "X_test, Y_test = generate_data_uniform_plus_normal(n_in_1_test, n_in_2_test, n_out_test, dim=dim, mean_c1=mean_c1, mean_c2=mean_c2, radius=radius, a_signal=a_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0533a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define machine learning models\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "binary_classifier = SVC(C=1, probability=True)\n",
    "oneclass_classifier = OneClassSVM(gamma='auto')\n",
    "\n",
    "# Compute conformity scores\n",
    "scores_cal_2s, scores_test_2s = compute_pu_scores(X_train, Y_train, X_cal, Y_cal, X_test, binary_classifier, two_step=True, oneclass_classifier = oneclass_classifier)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "254bbf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the conformity scores\n",
    "rcParams['figure.figsize'] = 11.7,8.27\n",
    "\n",
    "sns.histplot(x=scores_test_2s, hue=Y_test, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38052d22",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b225c3a-ad4f-4b1f-960e-4e52b3b3de1d",
   "metadata": {},
   "source": [
    "### Data generation and visualization\n",
    "Remarks: the data generation is just the same as I did last semester in the conformal inference cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae523cc-2a78-45bb-8e74-d63d22059835",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate data\n",
    "dim = 50\n",
    "mean_c1 = 1\n",
    "mean_c2 = -1\n",
    "radius = 4\n",
    "a_signal = sqrt(64)\n",
    "\n",
    "inliers_type1 = np.random.uniform(low=mean_c1 - radius, high=mean_c1 + radius, size=(50000, dim)) \\\n",
    "                + np.random.normal(loc=0, scale=1, size=(50000, dim))\n",
    "inliers_type2 = np.random.uniform(low=mean_c2 - radius, high=mean_c2 + radius, size=(50000, dim)) \\\n",
    "                + np.random.normal(loc=0, scale=1, size=(50000, dim))\n",
    "\n",
    "outlier_c1 = np.random.uniform(low=mean_c1 - radius, high=mean_c1 + radius, size=(25000, dim)) \\\n",
    "                       + a_signal * np.random.normal(loc=0, scale=1, size=(25000, dim))\n",
    "outlier_c2 = np.random.uniform(low=mean_c2 - radius, high=mean_c2 + radius, size=(25000, dim)) \\\n",
    "                       + a_signal * np.random.normal(loc=0, scale=1, size=(25000, dim))\n",
    "outliers = np.vstack((outlier_c1,outlier_c2))\n",
    "\n",
    "# Perform PCA to reduce to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "inliers_type1_pca = pca.fit_transform(inliers_type1)\n",
    "inliers_type2_pca = pca.fit_transform(inliers_type2)\n",
    "outliers_pca = pca.fit_transform(outliers)\n",
    "\n",
    "# Plot the distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(inliers_type1_pca[:1000, 0], inliers_type1_pca[:1000, 1], label='Inliers Type 1', alpha=0.5)\n",
    "plt.scatter(inliers_type2_pca[:1000, 0], inliers_type2_pca[:1000, 1], label='Inliers Type 2', alpha=0.5)\n",
    "plt.scatter(outliers_pca[:1000, 0], outliers_pca[:1000, 1], label='Outliers', alpha=0.5)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend()\n",
    "plt.title('Data Distributions After PCA')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f3520-adb5-4af4-acf4-b581f3feeb67",
   "metadata": {},
   "source": [
    "### A standard two-step PU learning procedure function\n",
    "this is a standard two step PU learning procedure dealing with guassian distributions, it contains the following steps:\n",
    "1. Generate datas with three different distributions, namely type1_inliers, type2_inliers, outliers\n",
    "2. Train a one class SVM on the positive training data, apply this SVM to a subset of unlabeled data, choose 10% reliable negative samples\n",
    "3. Train a binary SVM on the positive training data and the reliable negative samples, apply this SVM to unlabeled test data and get the 10% samples as negative(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03c011-4b9b-432d-b156-6a1e8cc16bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the PU learning procedure\n",
    "def run_pu_learning(n, prop_type1_train, prop_type2_train, prop_type1_unlabeled, prop_type2_unlabeled,\n",
    "                    prop_outliers_unlabeled):\n",
    "    # Results storage\n",
    "    results = []\n",
    "    proportions_within_predictions = []\n",
    "    proportions_reliable_negatives = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        iteration = _\n",
    "        # Sample 1000 data points for training\n",
    "        X_train_pos1, X_test_inliers1, _, _ = train_test_split(inliers_type1, np.zeros(50000),\n",
    "                                                               train_size=int(2000 * prop_type1_train),\n",
    "                                                               test_size=int(1000 * 2 * prop_type1_unlabeled))\n",
    "        X_train_pos2, X_test_inliers2, _, _ = train_test_split(inliers_type2, np.zeros(50000),\n",
    "                                                               train_size=int(2000 * prop_type2_train),\n",
    "                                                               test_size=int(1000 * 2 * prop_type2_unlabeled))\n",
    "        X_train = np.vstack((X_train_pos1, X_train_pos2))\n",
    "\n",
    "        # Ensure balanced representation of inliers in unlabeled data\n",
    "        X_unlabeled_inliers1, X_test_pos1, _, _ = train_test_split(X_test_inliers1,\n",
    "                                                                   np.zeros(int(1000 * 2 * prop_type1_unlabeled)),\n",
    "                                                                   train_size=int(1000 * prop_type1_unlabeled),\n",
    "                                                                   test_size=int(1000 * prop_type1_unlabeled))\n",
    "        X_unlabeled_inliers2, X_test_pos2, _, _ = train_test_split(X_test_inliers2,\n",
    "                                                                   np.zeros(int(1000 * 2 * prop_type2_unlabeled)),\n",
    "                                                                   train_size=int(1000 * prop_type2_unlabeled),\n",
    "                                                                   test_size=int(1000 * prop_type2_unlabeled))\n",
    "        X_unlabeled_outliers, X_test_neg, _, _ = train_test_split(outliers, np.zeros(50000),\n",
    "                                                                  train_size=int(1000 * prop_outliers_unlabeled),\n",
    "                                                                  test_size=int(1000 * prop_outliers_unlabeled))\n",
    "        X_unlabeled = np.vstack((X_unlabeled_inliers1, X_unlabeled_inliers2, X_unlabeled_outliers))\n",
    "\n",
    "        # Combine testing data\n",
    "        X_test = np.vstack((X_test_pos1, X_test_pos2, X_test_neg))\n",
    "        y_test = np.hstack((np.zeros(len(X_test_pos1) + len(X_test_pos2)), np.ones(len(X_test_neg))))\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_unlabeled_scaled = scaler.transform(X_unlabeled)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Step 1: Train a one-class SVM on positive samples\n",
    "        one_class_svm = OneClassSVM(gamma='auto').fit(X_train_scaled)\n",
    "\n",
    "        # Apply the one-class SVM to the unlabeled data\n",
    "        pred_unlabeled = one_class_svm.predict(X_unlabeled_scaled)\n",
    "        reliable_negatives_idx = np.where(pred_unlabeled == -1)[0]  # Select reliable negatives\n",
    "        X_reliable_negatives = X_unlabeled_scaled[reliable_negatives_idx]\n",
    "\n",
    "        # Combine the positive samples with reliable negatives\n",
    "        X_combined = np.vstack((X_train_scaled, X_reliable_negatives))\n",
    "        y_combined = np.hstack((np.zeros(len(X_train_scaled)), np.ones(len(X_reliable_negatives))))\n",
    "\n",
    "        # Step 2: Train a binary classifier on the selected positives and reliable negatives\n",
    "        final_clf = SVC(probability=True)\n",
    "        final_clf.fit(X_combined, y_combined)\n",
    "\n",
    "        # After fitting final_clf, predict probabilities\n",
    "        predictions_prob = final_clf.predict_proba(X_test_scaled)\n",
    "\n",
    "        # Adjust the threshold to achieve 50% predictions as 1\n",
    "        predictions = (predictions_prob[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "        # Calculate FDR and Power\n",
    "        false_positives = np.sum((predictions == 1) & (y_test == 0))\n",
    "        true_positives = np.sum((predictions == 1) & (y_test == 1))\n",
    "        total_predictions = np.sum(predictions == 1)\n",
    "\n",
    "        fdr = false_positives / total_predictions if total_predictions > 0 else 0\n",
    "        power = true_positives / np.sum(y_test == 1) if np.sum(y_test == 1) > 0 else 0\n",
    "\n",
    "        print(f\"Iteration {iteration}\")\n",
    "        print(f\"prop_type1_train:  {prop_type1_train}\")\n",
    "        print(f\"prop_type1_unlabeled:  {prop_type1_unlabeled}\")\n",
    "        print(f\"fdr:  {fdr}\")\n",
    "        print(f\"power: {power}\")\n",
    "\n",
    "        # Calculate proportions of type1, type2 inliers and outliers within predictions = 1\n",
    "        type1_pred = np.sum(predictions[:len(X_test_pos1)] == 1)\n",
    "        type2_pred = np.sum(predictions[len(X_test_pos1):len(X_test_pos1) + len(X_test_pos2)] == 1)\n",
    "        outliers_pred = np.sum(predictions[len(X_test_pos1) + len(X_test_pos2):] == 1)\n",
    "\n",
    "        total_pred = type1_pred + type2_pred + outliers_pred\n",
    "        prop_type1_pred = type1_pred / total_pred if total_pred > 0 else 0\n",
    "        prop_type2_pred = type2_pred / total_pred if total_pred > 0 else 0\n",
    "        prop_outliers_pred = outliers_pred / total_pred if total_pred > 0 else 0\n",
    "\n",
    "        proportions_within_predictions.append((prop_type1_pred, prop_type2_pred, prop_outliers_pred))\n",
    "\n",
    "        results.append((fdr, power))\n",
    "\n",
    "    return results, proportions_within_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64768829-178d-4925-9637-517cfe5dfe30",
   "metadata": {},
   "source": [
    "### Change the proportion of type1 data in both positive set and unlabeled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bdb3e3-d829-40ce-8995-473d8d263bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n = 20  # Number of iterations\n",
    "prop_type1_train_values = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "prop_type1_unlabeled_values = [0.5, 0.95, 0.99]  # Only extreme conditions\n",
    "prop_outliers = 0.1\n",
    "\n",
    "# Adjusted proportion combinations\n",
    "proportion_combinations = []\n",
    "for p1_train in prop_type1_train_values:\n",
    "    for p1_unlabeled in prop_type1_unlabeled_values:\n",
    "        p2_train = 1 - p1_train\n",
    "        p2_unlabeled = 1 - p1_unlabeled\n",
    "\n",
    "        proportion_combinations.append((p1_train, p2_train, p1_unlabeled, p2_unlabeled, prop_outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d6533-f5ad-4176-811d-9c3a29cd7f59",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the PU learning procedure for each combination of proportions\n",
    "all_results = {}\n",
    "all_proportions = {}\n",
    "for props in proportion_combinations:\n",
    "    prop_type1_train, prop_type2_train, prop_type1_unlabeled, prop_type2_unlabeled, prop_outliers_unlabeled = props\n",
    "    results, proportions_within_predictions = run_pu_learning(n, prop_type1_train, prop_type2_train,\n",
    "                                                              prop_type1_unlabeled, prop_type2_unlabeled,\n",
    "                                                              prop_outliers_unlabeled)\n",
    "    all_results[props] = results\n",
    "    all_proportions[props] = proportions_within_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f8001-3d8f-4a55-af44-4dcd669dcd47",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4c705-1b2d-4927-a3af-8b3c81cb64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "fdr_means = []\n",
    "power_means = []\n",
    "fdr_stds = []\n",
    "power_stds = []\n",
    "proportion_labels = []\n",
    "prop_type1_preds = []\n",
    "prop_type2_preds = []\n",
    "prop_outliers_preds = []\n",
    "\n",
    "for props, results in all_results.items():\n",
    "    fdrs, powers = zip(*results)\n",
    "    fdr_means.append(np.mean(fdrs))\n",
    "    power_means.append(np.mean(powers))\n",
    "    fdr_stds.append(np.std(fdrs) / sqrt(n))\n",
    "    power_stds.append(np.std(powers) / sqrt(n))\n",
    "    proportion_labels.append((props[0], props[2]))  # Using prop_type1_train and prop_type1_unlabeled for x-axis\n",
    "\n",
    "    type1_props, type2_props, outlier_props = zip(*all_proportions[props])\n",
    "    prop_type1_preds.append(np.mean(type1_props))\n",
    "    prop_type2_preds.append(np.mean(type2_props))\n",
    "    prop_outliers_preds.append(np.mean(outlier_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7017870-a8c6-4421-919d-6cf22e10771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results in a 3x3 grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(21, 24))\n",
    "\n",
    "for i, p1_unlabeled in enumerate(prop_type1_unlabeled_values):\n",
    "    # Filter results for the current prop_type1_unlabeled value\n",
    "    fdr_means_subset = [fdr_means[j] for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled]\n",
    "    power_means_subset = [power_means[j] for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled]\n",
    "    fdr_stds_subset = [fdr_stds[j] for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled]\n",
    "    power_stds_subset = [power_stds[j] for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled]\n",
    "\n",
    "    prop_type1_preds_subset = [prop_type1_preds[j] for j, props in enumerate(proportion_combinations) if\n",
    "                               props[2] == p1_unlabeled]\n",
    "    prop_type2_preds_subset = [prop_type2_preds[j] for j, props in enumerate(proportion_combinations) if\n",
    "                               props[2] == p1_unlabeled]\n",
    "    prop_outliers_preds_subset = [prop_outliers_preds[j] for j, props in enumerate(proportion_combinations) if\n",
    "                                  props[2] == p1_unlabeled]\n",
    "\n",
    "    # Plot FDR\n",
    "    ax = axes[0, i]\n",
    "    ax.errorbar(range(len(fdr_means_subset)), fdr_means_subset, yerr=fdr_stds_subset, fmt='o', linestyle='--',\n",
    "                label='FDR')\n",
    "    ax.set_xticks(range(len(fdr_means_subset)))\n",
    "    ax.set_xticklabels([f\"{props[0]}\" for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled],\n",
    "                       rotation=45)\n",
    "    ax.set_xlabel('Proportion of Type 1 in Positive Training Data')\n",
    "    ax.set_ylabel('FDR')\n",
    "    ax.set_title(f'FDR (prop_type1_unlabeled = {p1_unlabeled})')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Plot Power\n",
    "    ax = axes[1, i]\n",
    "    ax.errorbar(range(len(power_means_subset)), power_means_subset, yerr=power_stds_subset, fmt='o', linestyle='--',\n",
    "                label='Power')\n",
    "    ax.set_xticks(range(len(power_means_subset)))\n",
    "    ax.set_xticklabels([f\"{props[0]}\" for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled],\n",
    "                       rotation=45)\n",
    "    ax.set_xlabel('Proportion of Type 1 in Positive Training Data')\n",
    "    ax.set_ylabel('Power')\n",
    "    ax.set_title(f'Power (prop_type1_unlabeled = {p1_unlabeled})')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Plot Proportions within predictions = 1\n",
    "    ax = axes[2, i]\n",
    "    ax.plot(range(len(prop_type1_preds_subset)), prop_type1_preds_subset, 'o-', label='Type 1 Inliers')\n",
    "    ax.plot(range(len(prop_type2_preds_subset)), prop_type2_preds_subset, 'o-', label='Type 2 Inliers')\n",
    "    ax.plot(range(len(prop_outliers_preds_subset)), prop_outliers_preds_subset, 'o-', label='Outliers')\n",
    "    ax.set_xticks(range(len(prop_type1_preds_subset)))\n",
    "    ax.set_xticklabels([f\"{props[0]}\" for j, props in enumerate(proportion_combinations) if props[2] == p1_unlabeled],\n",
    "                       rotation=45)\n",
    "    ax.set_xlabel('Proportion of Type 1 in Positive Training Data')\n",
    "    ax.set_ylabel('Proportion within Predictions = 1')\n",
    "    ax.set_title(f'Predictions = 1 (prop_type1_unlabeled = {p1_unlabeled})')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dff0d-ce00-4e31-a735-7f8ab17db1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "704bf801-5d5b-41f6-99ca-a30e339c24ec",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. When the proportion of type1 data is small in training data, then PU learning tends to regard inliers as negative in the unlabeled dataset\n",
    "2. The results depend heavily on the “fit” between the machine learning algorithm and the data. (Compared to the conformal inference experiment, it **regards every data as negative** if outliers are not so obvious and was't been standard scaled)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66318c72-e06c-48f3-9103-e1dc5d2d6137",
   "metadata": {},
   "source": [
    "#### Puzzle(solved):\n",
    "1. Why FDR is so high?\n",
    "   the data is almost the same in my previous experiment in the conformal inference cases. However, FDR here is very high.\n",
    "   \n",
    "**Possible Explannation**: the two-step PUL double the prediction error, since it first introduce one-class svm to identify some reliable negative data, and use it to train a binary classifier.(double error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8e9a2-04ce-4e40-a9bf-37a975ba2c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14c606-a1af-4917-b884-8b608a910c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
